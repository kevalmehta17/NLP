# Lets start with NLP basic:-

# Corpus :-  Paragraph
# Documents:- sentences
# vocabulary:- unique  words
# words:- tokens

# ----------------------------Tokenization-----------------------------
# Tokenization:- Tokenization is the process of breaking down a text into smaller components, such as sentences or words. This is a fundamental step in natural language processing (NLP) that allows for easier analysis and understanding of the text.

# ex :- My name is Keval and i have a interest in teaching ML,NLP and DL.I am also a youtuber.
# Token :- sentence
# 1) My name is Keval and i have a interest in teaching ML,NLP and DL.
# 2) I am also a youtuber.
# Token :- words
# 1) My 2) name 3) is 4) Keval 5) and 6) i 7) have 8) a 9) interest 10) in 11) teaching 12) ML,NLP and DL. 13) I 14) am 15) also 16) a 17) youtuber.

# --------------------------- Vocabulary :- unique words----------------------
# I like to drink Apple juice.My friend likes to drink Mango juice.
# Token :- words
# 1) I 2) like 3) to 4) drink 5) Apple 6) juice. 7) My 8) friend 9) likes 10) to 11) drink 12) Mango 13) juice.
# Vocabulary  :- unique words 
# 1) I 2) like 3) to 4) drink 5) Apple 6) juice. 7) My 8) friend 9) likes 10) Mango.