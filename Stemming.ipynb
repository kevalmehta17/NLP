{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b80347ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming :- Stemming is the process of reducing a word to its base or root form.\n",
    "# Example: The stem of the word \"running\" is \"run\".\n",
    "words = [\"running\", \"ran\",\"writing\", \"easily\", \"fairly\", \"happily\", \"happiness\",\"congratulations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703333b6",
   "metadata": {},
   "source": [
    "Porter Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0e43126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> run\n",
      "ran ---> ran\n",
      "writing ---> write\n",
      "easily ---> easili\n",
      "fairly ---> fairli\n",
      "happily ---> happili\n",
      "happiness ---> happi\n",
      "congratulations ---> congratul\n"
     ]
    }
   ],
   "source": [
    "# Porter Stemmer :- It is one of the most common stemming algorithms. It is designed to remove common morphological and inflectional endings from words in English.\n",
    "from nltk.stem import  PorterStemmer\n",
    "# Create a PorterStemmer object\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Apply stemming to each word in the list\n",
    "for word in words:\n",
    "    print(word+ \" ---> \" + porter_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61196194",
   "metadata": {},
   "source": [
    "RegexStemmer Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex Stemmer :- It is a stemmer that uses regular expressions to remove suffixes from words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d506acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlikely ---> likely\n",
      "running ---> runn\n",
      "ran ---> ran\n",
      "agreeable ---> agree\n",
      "grapes ---> grape\n",
      "eats ---> eat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Create a RegexpStemmer object with a specific pattern\n",
    "regex_stemmer = RegexpStemmer('^un|ing$|s$|e$|able$', min=4)\n",
    "\n",
    "input_words = [\"unlikely\",\"running\", \"ran\", \"agreeable\", \"grapes\", \"eats\"]\n",
    "\n",
    "# Apply regex stemming to each word in the list\n",
    "for word in input_words:\n",
    "    print(word + \" ---> \" + regex_stemmer.stem(word))\n",
    "\n",
    "# -----or------\n",
    "# output_words = [regex_stemmer.stem(word) for word in input_words]\n",
    "# output_words\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a33f47",
   "metadata": {},
   "source": [
    "Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball stemmer :- It is an improvement over the Porter Stemmer and supports multiple languages. It is designed to be more aggressive in removing suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100df533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running --> run\n",
      "ran --> ran\n",
      "writing --> write\n",
      "easily --> easili\n",
      "fairly --> fair\n",
      "happily --> happili\n",
      "happiness --> happi\n",
      "congratulations --> congratul\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Create a SnowballStemmer object for English\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Apply snowball stemming to each word in the list\n",
    "\n",
    "snowball_words = [\"running\", \"ran\", \"writing\", \"easily\", \"fairly\", \"happily\", \"happiness\", \"congratulations\"]\n",
    "\n",
    "for word in snowball_words:\n",
    "    print(word + \" --> \" + snowball_stemmer.stem(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc9e5ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli sportingli\n",
      "fair sport\n"
     ]
    }
   ],
   "source": [
    "# lets compare the Porter and Snowball stemmers\n",
    "\n",
    "print(porter_stemmer.stem(\"fairly\"),porter_stemmer.stem(\"sportingly\")\n",
    ")\n",
    "print(snowball_stemmer.stem(\"fairly\"),snowball_stemmer.stem(\"sportingly\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66c9ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compare all three stemmers\n",
    "# Which is the best stemmer?\n",
    "# Compare the output of all three stemmers for the same set of words\n",
    "\n",
    "# Discussion:\n",
    "# Porter Stemmer: Simple and widely used, but sometimes less accurate.\n",
    "# Snowball Stemmer: More aggressive and consistent, supports multiple languages, often preferred for English.\n",
    "# Regex Stemmer: Highly customizable, but may not generalize well without careful pattern design.\n",
    "# In practice, Snowball is generally considered the best for English due to its balance of accuracy and consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
